{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    " \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    " \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "\n",
    "# https://github.com/affinelayer/pix2pix-tensorflow\n",
    "\n",
    "c = 1\n",
    "#testinput=input(\"test input name:\")\n",
    "while (c < 1):\n",
    "        b = 1\n",
    "        while ( b < 51):\n",
    "            #foldername=input(\"model name:\") \n",
    "            #testinput=input(\"test input name:\")\n",
    "            train_input_dir=\"E:/107568025(F)/picture/train_pic/\" + str(b) + \"/stick\"       # 训练集输入\n",
    "            train_output_dir=\"E:/107568025(F)/picture/pix2pix_out/\" + str(b) + \"/trainout/\" # 训练集输出\n",
    "            if not os.path.exists(train_output_dir):\n",
    "                os.makedirs(train_output_dir)\n",
    "            test_input_dir=\"E:/107568025(F)/picture/test_pic/ALL_stick\"         # 测试集输入\n",
    "            test_output_dir=\"E:/107568025(F)/picture/test_out/\" + str(b) + \"/\"   #測試集輸出\n",
    "            if not os.path.exists(test_output_dir):\n",
    "                os.makedirs(test_output_dir)\n",
    "            checkpoint=\"E:/107568025(F)/picture/pix2pix_out/\" + str(b) + \"/trainout/\"        # 保存结果的目录\n",
    "            if not os.path.exists(checkpoint):\n",
    "                os.makedirs(checkpoint)\n",
    "\n",
    "            seed=None\n",
    "            max_steps=None     # number of training steps (0 to disable)\n",
    "            max_epochs=200     # number of training epochs\n",
    "\n",
    "            progress_freq=50   # display progress every progress_freq steps\n",
    "            trace_freq=0       # trace execution every trace_freq steps\n",
    "            display_freq=50     # write current training images every display_freq steps\n",
    "            save_freq=500     # save model every save_freq steps, 0 to disable\n",
    "\n",
    "            separable_conv=False    # use separable convolutions in the generator\n",
    "            aspect_ratio=1.0        # aspect ratio of output images (width/height)\n",
    "            batch_size=1            # help=\"number of images in batch\")\n",
    "            which_direction=\"BtoA\"  # choices=[\"AtoB\", \"BtoA\"])\n",
    "            ngf=64                  # help=\"number of generator filters in first conv layer\")\n",
    "            ndf=64                  # help=\"number of discriminator filters in first conv layer\")\n",
    "            scale_size=256          # help=\"scale images to this size before cropping to 256x256\")\n",
    "            flip=False              # flip images horizontally\n",
    "            no_flip=True            # don't flip images horizontally\n",
    "\n",
    "            lr=0.0002        # initial learning rate for adam\n",
    "            beta1=0.5        # momentum term of adam\n",
    "            l1_weight=100.0  # weight on L1 term for generator gradient\n",
    "            gan_weight=1.0   # weight on GAN term for generator gradient\n",
    "\n",
    "            output_filetype=\"jpeg\"  # 输出图像的格式\n",
    "\n",
    "            EPS = 1e-12       # 极小数，防止梯度为损失为0\n",
    "            CROP_SIZE = 256   # 图片的裁剪大小\n",
    "\n",
    "            # 命名元组,用于存放加载的数据集合创建好的模型\n",
    "            Examples = collections.namedtuple(\"Examples\", \"paths, inputs, targets, count, steps_per_epoch\")\n",
    "            Model = collections.namedtuple(\"Model\", \"outputs, predict_real, predict_fake, discrim_loss, discrim_grads_and_vars, gen_loss_GAN, gen_loss_L1, gen_grads_and_vars, train\")\n",
    "            # 图像预处理 [0, 1] => [-1, 1]\n",
    "            def preprocess(image):\n",
    "                with tf.name_scope(\"preprocess\"):        \n",
    "                    return image * 2 - 1\n",
    "\n",
    "            # 图像后处理[-1, 1] => [0, 1]\n",
    "            def deprocess(image):\n",
    "                with tf.name_scope(\"deprocess\"):        \n",
    "                    return (image + 1) / 2\n",
    "\n",
    "\n",
    "            # 判别器的卷积定义，batch_input为 [ batch , 256 , 256 , 6 ]\n",
    "            def discrim_conv(batch_input, out_channels, stride):\n",
    "                # [ batch , 256 , 256 , 6 ] ===>[ batch , 258 , 258 , 6 ]\n",
    "                padded_input = tf.pad(batch_input, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"CONSTANT\")\n",
    "                '''\n",
    "                [0,0]: 第一维batch大小不扩充\n",
    "                [1,1]：第二维图像宽度左右各扩充一列，用0填充\n",
    "                [1,1]：第三维图像高度上下各扩充一列，用0填充\n",
    "                [0,0]：第四维图像通道不做扩充\n",
    "                '''\n",
    "                return tf.layers.conv2d(padded_input, out_channels, kernel_size=4, strides=(stride, stride), padding=\"valid\", kernel_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "\n",
    "\n",
    "            # 生成器的卷积定义，卷积核为4*4，步长为2，输出图像为输入的一半\n",
    "            def gen_conv(batch_input, out_channels):\n",
    "                # [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]\n",
    "                initializer = tf.random_normal_initializer(0, 0.02)\n",
    "                if separable_conv:\n",
    "                    return tf.layers.separable_conv2d(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\", depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "                else:\n",
    "                    return tf.layers.conv2d(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\", kernel_initializer=initializer)\n",
    "\n",
    "            # 生成器的反卷积定义\n",
    "            def gen_deconv(batch_input, out_channels):\n",
    "                # [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]\n",
    "                initializer = tf.random_normal_initializer(0, 0.02)\n",
    "                if separable_conv:\n",
    "                    _b, h, w, _c = batch_input.shape\n",
    "                    resized_input = tf.image.resize_images(batch_input, [h * 2, w * 2], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "                    return tf.layers.separable_conv2d(resized_input, out_channels, kernel_size=4, strides=(1, 1), padding=\"same\", depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "                else:\n",
    "                    return tf.layers.conv2d_transpose(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\", kernel_initializer=initializer)\n",
    "\n",
    "            # 定义LReLu激活函数\n",
    "            def lrelu(x, a):\n",
    "                with tf.name_scope(\"lrelu\"):\n",
    "                    # adding these together creates the leak part and linear part\n",
    "                    # then cancels them out by subtracting/adding an absolute value term\n",
    "                    # leak: a*x/2 - a*abs(x)/2\n",
    "                    # linear: x/2 + abs(x)/2\n",
    "\n",
    "                    # this block looks like it has 2 inputs on the graph unless we do this\n",
    "                    x = tf.identity(x)\n",
    "                    return (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)\n",
    "\n",
    "            # 批量归一化图像\n",
    "            def batchnorm(inputs):\n",
    "                return tf.layers.batch_normalization(inputs, axis=3, epsilon=1e-5, momentum=0.1, training=True, gamma_initializer=tf.random_normal_initializer(1.0, 0.02))\n",
    "\n",
    "            # 检查图像的维度\n",
    "            def check_image(image):\n",
    "                assertion = tf.assert_equal(tf.shape(image)[-1], 3, message=\"image must have 3 color channels\")\n",
    "                with tf.control_dependencies([assertion]):\n",
    "                    image = tf.identity(image)\n",
    "\n",
    "                if image.get_shape().ndims not in (3, 4):\n",
    "                    raise ValueError(\"image must be either 3 or 4 dimensions\")\n",
    "\n",
    "                # make the last dimension 3 so that you can unstack the colors\n",
    "                shape = list(image.get_shape())\n",
    "                shape[-1] = 3\n",
    "                image.set_shape(shape)\n",
    "                return image\n",
    "\n",
    "\n",
    "            # 去除文件的后缀，获取文件名\n",
    "            def get_name(path):\n",
    "                # os.path.basename(),返回path最后的文件名。若path以/或\\结尾，那么就会返回空值。\n",
    "                # os.path.splitext(),分离文件名与扩展名；默认返回(fname,fextension)元组\n",
    "                name, _ = os.path.splitext(os.path.basename(path))\n",
    "                return name\n",
    "\n",
    "\n",
    "            # 加载数据集，从文件读取-->解码-->归一化--->拆分为输入和目标-->像素转为[-1,1]-->转变形状\n",
    "            def load_examples(input_dir):\n",
    "                if input_dir is None or not os.path.exists(input_dir):\n",
    "                    raise Exception(\"input_dir does not exist\")\n",
    "\n",
    "                # 匹配第一个参数的路径中所有的符合条件的文件，并将其以list的形式返回。    \n",
    "                input_paths = glob.glob(os.path.join(input_dir, \"*.jepg\"))    \n",
    "\n",
    "                # 图像解码器\n",
    "                decode = tf.image.decode_jpeg\n",
    "                if len(input_paths) == 0:\n",
    "                    input_paths = glob.glob(os.path.join(input_dir, \"*.jpeg\"))\n",
    "                    decode = tf.image.decode_png\n",
    "\n",
    "                if len(input_paths) == 0:\n",
    "                    raise Exception(\"input_dir contains no image files\")\n",
    "\n",
    "                # 如果文件名是数字，则用数字进行排序，否则用字母排序    \n",
    "                if all(get_name(path).isdigit() for path in input_paths):\n",
    "                    input_paths = sorted(input_paths, key=lambda path: int(get_name(path)))\n",
    "                else:\n",
    "                    input_paths = sorted(input_paths)\n",
    "\n",
    "                sess = tf.Session()\n",
    "\n",
    "                with tf.name_scope(\"load_images\"):\n",
    "                    # 把我们需要的全部文件打包为一个tf内部的queue类型，之后tf开文件就从这个queue中取目录了，\n",
    "                    # 如果是训练模式时，shuffle为True\n",
    "                    path_queue = tf.train.string_input_producer(input_paths, shuffle=True)\n",
    "\n",
    "                    # Read的输出将是一个文件名（key）和该文件的内容（value,每次读取一个文件，分多次读取）。\n",
    "                    reader = tf.WholeFileReader()\n",
    "                    paths, contents = reader.read(path_queue)\n",
    "\n",
    "                    # 对文件进行解码并且对图片作归一化处理\n",
    "                    raw_input = decode(contents)\n",
    "                    raw_input = tf.image.convert_image_dtype(raw_input, dtype=tf.float32) # 归一化处理\n",
    "\n",
    "                    # 判断两个值知否相等，如果不等抛出异常\n",
    "                    assertion = tf.assert_equal(tf.shape(raw_input)[2], 3, message=\"image does not have 3 channels\")\n",
    "                    '''\n",
    "                      对于control_dependencies这个管理器，只有当里面的操作是一个op时，才会生效，也就是先执行传入的\n",
    "                    参数op，再执行里面的op。如果里面的操作不是定义的op，图中就不会形成一个节点，这样该管理器就失效了。\n",
    "                    tf.identity是返回一个一模一样新的tensor的op，这会增加一个新节点到gragh中，这时control_dependencies就会生效.\n",
    "                    '''\n",
    "                    with tf.control_dependencies([assertion]):\n",
    "                        raw_input = tf.identity(raw_input)\n",
    "\n",
    "                    raw_input.set_shape([None, None, 3])\n",
    "\n",
    "                    # 图像值由[0,1]--->[-1, 1]\n",
    "                    width = tf.shape(raw_input)[1] # [height, width, channels]\n",
    "                    a_images = preprocess(raw_input[:,:width//2,:])  # 256*256*3\n",
    "                    b_images = preprocess(raw_input[:,width//2:,:])  # 256*256*3\n",
    "\n",
    "                # 这里的which_direction为：BtoA\n",
    "                if which_direction == \"AtoB\":\n",
    "                    inputs, targets = [a_images, b_images]\n",
    "                elif which_direction == \"BtoA\":\n",
    "                    inputs, targets = [b_images, a_images]\n",
    "                else:\n",
    "                    raise Exception(\"invalid direction\")\n",
    "\n",
    "                # synchronize seed for image operations so that we do the same operations to both\n",
    "                # input and output images\n",
    "                seed = random.randint(0, 2**31 - 1)    \n",
    "\n",
    "                # 图像预处理，翻转、改变形状\n",
    "                with tf.name_scope(\"input_images\"):\n",
    "                    input_images = transform(inputs)\n",
    "                with tf.name_scope(\"target_images\"):\n",
    "                    target_images = transform(targets)\n",
    "\n",
    "                # 获得输入图像、目标图像的batch块\n",
    "                paths_batch, inputs_batch, targets_batch = tf.train.batch([paths, input_images, target_images], batch_size=batch_size)\n",
    "                steps_per_epoch = int(math.ceil(len(input_paths) / batch_size))\n",
    "\n",
    "                return Examples(\n",
    "                    paths=paths_batch,               # 输入的文件名块\n",
    "                    inputs=inputs_batch,             # 输入的图像块 \n",
    "                    targets=targets_batch,           # 目标图像块\n",
    "                    count=len(input_paths),          # 数据集的大小\n",
    "                    steps_per_epoch=steps_per_epoch, # batch的个数\n",
    "                )\n",
    "\n",
    "\n",
    "            # 图像预处理，翻转、改变形状\n",
    "            def transform(image):\n",
    "                r = image\n",
    "                if flip:\n",
    "                    r = tf.image.random_flip_left_right(r, seed=seed)\n",
    "\n",
    "                # area produces a nice downscaling, but does nearest neighbor for upscaling\n",
    "                # assume we're going to be doing downscaling here\n",
    "                r = tf.image.resize_images(r, [scale_size, scale_size], method=tf.image.ResizeMethod.AREA)\n",
    "\n",
    "                offset = tf.cast(tf.floor(tf.random_uniform([2], 0, scale_size - CROP_SIZE + 1, seed=seed)), dtype=tf.int32)\n",
    "                if scale_size > CROP_SIZE:\n",
    "                    r = tf.image.crop_to_bounding_box(r, offset[0], offset[1], CROP_SIZE, CROP_SIZE)\n",
    "                elif scale_size < CROP_SIZE:\n",
    "                    raise Exception(\"scale size cannot be less than crop size\")\n",
    "                return r\n",
    "\n",
    "\n",
    "            #创建生成器，这是一个编码解码器的变种，输入输出均为：256*256*3, 像素值为[-1,1]\n",
    "            def create_generator(generator_inputs, generator_outputs_channels):\n",
    "                layers = []\n",
    "\n",
    "                # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
    "                with tf.variable_scope(\"encoder_1\"):\n",
    "                    output = gen_conv(generator_inputs, ngf) # ngf为第一个卷积层的卷积核核数量，默认为 64\n",
    "                    layers.append(output)\n",
    "\n",
    "                layer_specs = [\n",
    "                    ngf * 2, # encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]\n",
    "                    ngf * 4, # encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]\n",
    "                    ngf * 8, # encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]\n",
    "                    ngf * 8, # encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]\n",
    "                    ngf * 8, # encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]\n",
    "                    ngf * 8, # encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]\n",
    "                    ngf * 8, # encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]\n",
    "                ]\n",
    "\n",
    "                # 卷积的编码器\n",
    "                for out_channels in layer_specs:\n",
    "                    with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "                        # 对最后一层使用激活函数\n",
    "                        rectified = lrelu(layers[-1], 0.2)\n",
    "                        # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "                        convolved = gen_conv(rectified, out_channels)\n",
    "                        output = batchnorm(convolved)\n",
    "                        layers.append(output)\n",
    "\n",
    "                layer_specs = [\n",
    "                    (ngf * 8, 0.5),   # decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]\n",
    "                    (ngf * 8, 0.5),   # decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]\n",
    "                    (ngf * 8, 0.5),   # decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]\n",
    "                    (ngf * 8, 0.0),   # decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]\n",
    "                    (ngf * 4, 0.0),   # decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]\n",
    "                    (ngf * 2, 0.0),   # decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]\n",
    "                    (ngf, 0.0),       # decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]\n",
    "                ]\n",
    "\n",
    "                # 卷积的解码器\n",
    "                num_encoder_layers = len(layers) # 8\n",
    "                for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
    "                    skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "                    with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "                        if decoder_layer == 0:\n",
    "                            # first decoder layer doesn't have skip connections\n",
    "                            # since it is directly connected to the skip_layer\n",
    "                            input = layers[-1]\n",
    "                        else:\n",
    "                            input = tf.concat([layers[-1], layers[skip_layer]], axis=3)\n",
    "\n",
    "                        rectified = tf.nn.relu(input)\n",
    "                        # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
    "                        output = gen_deconv(rectified, out_channels)\n",
    "                        output = batchnorm(output)\n",
    "\n",
    "                        if dropout > 0.0:\n",
    "                            output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "                        layers.append(output)\n",
    "\n",
    "                # decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]\n",
    "                with tf.variable_scope(\"decoder_1\"):\n",
    "                    input = tf.concat([layers[-1], layers[0]], axis=3)\n",
    "                    rectified = tf.nn.relu(input)\n",
    "                    output = gen_deconv(rectified, generator_outputs_channels)\n",
    "                    output = tf.tanh(output)\n",
    "                    layers.append(output)\n",
    "\n",
    "                return layers[-1]\n",
    "\n",
    "\n",
    "\n",
    "            # 创建判别器，输入生成的图像和真实的图像：两个[batch,256,256,3],元素值值[-1,1]，输出:[batch,30,30,1],元素值为概率\n",
    "            def create_discriminator(discrim_inputs, discrim_targets):\n",
    "                n_layers = 3\n",
    "                layers = []\n",
    "\n",
    "                # 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]\n",
    "                input = tf.concat([discrim_inputs, discrim_targets], axis=3)\n",
    "\n",
    "                # layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]\n",
    "                with tf.variable_scope(\"layer_1\"):\n",
    "                    convolved = discrim_conv(input, ndf, stride=2)\n",
    "                    rectified = lrelu(convolved, 0.2)\n",
    "                    layers.append(rectified)\n",
    "\n",
    "                # layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]\n",
    "                # layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]\n",
    "                # layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]\n",
    "                for i in range(n_layers):\n",
    "                    with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                        out_channels = ndf * min(2**(i+1), 8)\n",
    "                        stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "                        convolved = discrim_conv(layers[-1], out_channels, stride=stride)\n",
    "                        normalized = batchnorm(convolved)\n",
    "                        rectified = lrelu(normalized, 0.2)\n",
    "                        layers.append(rectified)\n",
    "\n",
    "                # layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]\n",
    "                with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "                    convolved = discrim_conv(rectified, out_channels=1, stride=1)\n",
    "                    output = tf.sigmoid(convolved)\n",
    "                    layers.append(output)\n",
    "\n",
    "                return layers[-1]\n",
    "\n",
    "            # 创建Pix2Pix模型，inputs和targets形状为：[batch_size, height, width, channels]\n",
    "            def create_model(inputs, targets):\n",
    "                with tf.variable_scope(\"generator\"):\n",
    "                    out_channels = int(targets.get_shape()[-1])\n",
    "                    outputs = create_generator(inputs, out_channels)\n",
    "\n",
    "                # create two copies of discriminator, one for real pairs and one for fake pairs\n",
    "                # they share the same underlying variables\n",
    "                with tf.name_scope(\"real_discriminator\"):\n",
    "                    with tf.variable_scope(\"discriminator\"):\n",
    "                        # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "                        predict_real = create_discriminator(inputs, targets) # 条件变量图像和真实图像\n",
    "\n",
    "                with tf.name_scope(\"fake_discriminator\"):\n",
    "                    with tf.variable_scope(\"discriminator\", reuse=True):\n",
    "                        # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "                        predict_fake = create_discriminator(inputs, outputs) # 条件变量图像和生成的图像\n",
    "\n",
    "                # 判别器的损失，判别器希望V(G,D)尽可能大\n",
    "                with tf.name_scope(\"discriminator_loss\"):\n",
    "                    # minimizing -tf.log will try to get inputs to 1\n",
    "                    # predict_real => 1\n",
    "                    # predict_fake => 0\n",
    "                    discrim_loss = tf.reduce_mean(-(tf.log(predict_real + EPS) + tf.log(1 - predict_fake + EPS)))\n",
    "\n",
    "                # 生成器的损失，生成器希望V(G,D)尽可能小\n",
    "                with tf.name_scope(\"generator_loss\"):\n",
    "                    # predict_fake => 1\n",
    "                    # abs(targets - outputs) => 0\n",
    "                    gen_loss_GAN = tf.reduce_mean(-tf.log(predict_fake + EPS))  \n",
    "                    gen_loss_L1 = tf.reduce_mean(tf.abs(targets - outputs))\n",
    "                    gen_loss = gen_loss_GAN * gan_weight + gen_loss_L1 * l1_weight\n",
    "\n",
    "                # 判别器训练\n",
    "                with tf.name_scope(\"discriminator_train\"):\n",
    "                    # 判别器需要优化的参数\n",
    "                    discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
    "                    # 优化器定义\n",
    "                    discrim_optim = tf.train.AdamOptimizer(lr, beta1)\n",
    "                    # 计算损失函数对优化参数的梯度\n",
    "                    discrim_grads_and_vars = discrim_optim.compute_gradients(discrim_loss, var_list=discrim_tvars)\n",
    "                    # 更新该梯度所对应的参数的状态，返回一个op\n",
    "                    discrim_train = discrim_optim.apply_gradients(discrim_grads_and_vars)\n",
    "\n",
    "                # 生成器训练\n",
    "                with tf.name_scope(\"generator_train\"):\n",
    "                    with tf.control_dependencies([discrim_train]):\n",
    "                        # 生成器需要优化的参数列表\n",
    "                        gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
    "                        # 定义优化器\n",
    "                        gen_optim = tf.train.AdamOptimizer(lr, beta1)\n",
    "                        # 计算需要优化的参数的梯度\n",
    "                        gen_grads_and_vars = gen_optim.compute_gradients(gen_loss, var_list=gen_tvars)\n",
    "                        # 更新该梯度所对应的参数的状态，返回一个op\n",
    "                        gen_train = gen_optim.apply_gradients(gen_grads_and_vars)\n",
    "\n",
    "                '''\n",
    "                  在采用随机梯度下降算法训练神经网络时，使用 tf.train.ExponentialMovingAverage 滑动平均操作的意义在于\n",
    "                提高模型在测试数据上的健壮性（robustness）。tensorflow 下的 tf.train.ExponentialMovingAverage 需要\n",
    "                提供一个衰减率（decay）。该衰减率用于控制模型更新的速度。该衰减率用于控制模型更新的速度，\n",
    "                ExponentialMovingAverage 对每一个（待更新训练学习的）变量（variable）都会维护一个影子变量\n",
    "                （shadow variable）。影子变量的初始值就是这个变量的初始值，\n",
    "                    shadow_variable=decay×shadow_variable+(1−decay)×variable\n",
    "                '''\n",
    "                ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "                update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])\n",
    "\n",
    "                # \n",
    "                global_step = tf.train.get_or_create_global_step()\n",
    "                incr_global_step = tf.assign(global_step, global_step+1)\n",
    "\n",
    "                return Model(\n",
    "                    predict_real=predict_real,  # 条件变量(输入图像)和真实图像之间的概率值，形状为；[batch,30,30,1]\n",
    "                    predict_fake=predict_fake,  # 条件变量(输入图像)和生成图像之间的概率值，形状为；[batch,30,30,1]\n",
    "                    discrim_loss=ema.average(discrim_loss),          # 判别器损失\n",
    "                    discrim_grads_and_vars=discrim_grads_and_vars,   # 判别器需要优化的参数和对应的梯度\n",
    "                    gen_loss_GAN=ema.average(gen_loss_GAN),          # 生成器的损失\n",
    "                    gen_loss_L1=ema.average(gen_loss_L1),            # 生成器的 L1损失\n",
    "                    gen_grads_and_vars=gen_grads_and_vars,           # 生成器需要优化的参数和对应的梯度\n",
    "                    outputs=outputs,                                 # 生成器生成的图片\n",
    "                    train=tf.group(update_losses, incr_global_step, gen_train),  # 打包需要run的操作op\n",
    "                )\n",
    "\n",
    "\n",
    "            # 保存图像\n",
    "            def save_images(output_dir,fetches, step=None):\n",
    "                image_dir = os.path.join(output_dir, \"images\")\n",
    "                if not os.path.exists(image_dir):\n",
    "                    os.makedirs(image_dir)\n",
    "\n",
    "                filesets = []\n",
    "                for i, in_path in enumerate(fetches[\"paths\"]):\n",
    "                    name, _ = os.path.splitext(os.path.basename(in_path.decode(\"utf8\")))\n",
    "                    fileset = {\"name\": name, \"step\": step}\n",
    "                    for kind in [\"inputs\", \"outputs\", \"targets\"]:\n",
    "                        filename = name + \"-\" + kind + \".png\"\n",
    "                        if step is not None:\n",
    "                            filename = \"%08d-%s\" % (step, filename)\n",
    "                        fileset[kind] = filename\n",
    "                        out_path = os.path.join(image_dir, filename)\n",
    "                        contents = fetches[kind][i]\n",
    "                        with open(out_path, \"wb\") as f:\n",
    "                            f.write(contents)\n",
    "                    filesets.append(fileset)\n",
    "                return filesets\n",
    "\n",
    "\n",
    "            # 将结果写入HTML网页\n",
    "            def append_index(output_dir,filesets, step=False):\n",
    "                index_path = os.path.join(output_dir, \"index.html\")\n",
    "                if os.path.exists(index_path):\n",
    "                    index = open(index_path, \"a\")\n",
    "                else:\n",
    "                    index = open(index_path, \"w\")\n",
    "                    index.write(\"<html><body><table><tr>\")\n",
    "                    if step:\n",
    "                        index.write(\"<th>step</th>\")\n",
    "                    index.write(\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\")\n",
    "\n",
    "                for fileset in filesets:\n",
    "                    index.write(\"<tr>\")\n",
    "\n",
    "                    if step:\n",
    "                        index.write(\"<td>%d</td>\" % fileset[\"step\"])\n",
    "                    index.write(\"<td>%s</td>\" % fileset[\"name\"])\n",
    "\n",
    "                    for kind in [\"inputs\", \"outputs\", \"targets\"]:\n",
    "                        index.write(\"<td><img src='images/%s'></td>\" % fileset[kind])\n",
    "\n",
    "                    index.write(\"</tr>\")\n",
    "                return index_path\n",
    "\n",
    "\n",
    "            # 转变图像的尺寸、并且将[0,1]--->[0,255]\n",
    "            def convert(image):\n",
    "                if aspect_ratio != 1.0:\n",
    "                    # upscale to correct aspect ratio\n",
    "                    size = [CROP_SIZE, int(round(CROP_SIZE * a.aspect_ratio))]\n",
    "                    image = tf.image.resize_images(image, size=size, method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "                # 将数据的类型转换为8位无符号整型  \n",
    "                return tf.image.convert_image_dtype(image, dtype=tf.uint8, saturate=True) \n",
    "\n",
    "\n",
    "            # 主函数\n",
    "            def train():\n",
    "                # 设置随机数种子的值\n",
    "                global seed\n",
    "                if seed is None:\n",
    "                    seed = random.randint(0, 2**31 - 1)\n",
    "\n",
    "                tf.set_random_seed(seed)\n",
    "                np.random.seed(seed)\n",
    "                random.seed(seed)\n",
    "\n",
    "                # 创建目录\n",
    "                if not os.path.exists(train_output_dir):\n",
    "                    os.makedirs(train_output_dir)\n",
    "\n",
    "\n",
    "                # 加载数据集，得到输入数据和目标数据并把范围变为 :[-1,1]\n",
    "                examples = load_examples(train_input_dir)\n",
    "                print(\"load successful ! examples count = %d\" % examples.count)\n",
    "\n",
    "                # 创建模型，inputs和targets是：[batch_size, height, width, channels]\n",
    "                # 返回值：\n",
    "                model = create_model(examples.inputs, examples.targets)\n",
    "                print (\"create model successful!\")\n",
    "\n",
    "\n",
    "                #图像处理[-1, 1] => [0, 1]\n",
    "                inputs = deprocess(examples.inputs)  \n",
    "                targets = deprocess(examples.targets)\n",
    "                outputs = deprocess(model.outputs)\n",
    "\n",
    "                # 把[0,1]的像素点转为RGB值：[0,255]\n",
    "                with tf.name_scope(\"convert_inputs\"):\n",
    "                    converted_inputs = convert(inputs)\n",
    "                with tf.name_scope(\"convert_targets\"):\n",
    "                    converted_targets = convert(targets)\n",
    "                with tf.name_scope(\"convert_outputs\"):\n",
    "                    converted_outputs = convert(outputs)\n",
    "\n",
    "                # 对图像进行编码以便于保存\n",
    "                with tf.name_scope(\"encode_images\"):\n",
    "                    display_fetches = {\n",
    "                        \"paths\": examples.paths,\n",
    "                        # tf.map_fn接受一个函数对象和集合，用函数对集合中每个元素分别处理\n",
    "                        \"inputs\": tf.map_fn(tf.image.encode_png, converted_inputs, dtype=tf.string, name=\"input_pngs\"),\n",
    "                        \"targets\": tf.map_fn(tf.image.encode_png, converted_targets, dtype=tf.string, name=\"target_pngs\"),\n",
    "                        \"outputs\": tf.map_fn(tf.image.encode_png, converted_outputs, dtype=tf.string, name=\"output_pngs\"),\n",
    "                    }\n",
    "\n",
    "                with tf.name_scope(\"parameter_count\"):\n",
    "                    parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables()])\n",
    "\n",
    "                # 只保存最新一个checkpoint\n",
    "                saver = tf.train.Saver(max_to_keep=20)     \n",
    "\n",
    "                init=tf.global_variables_initializer()\n",
    "\n",
    "                with tf.Session() as sess:\n",
    "                    sess.run(init)\n",
    "                    print(\"parameter_count =\", sess.run(parameter_count))\n",
    "                    if max_epochs is not None:\n",
    "                        max_steps = examples.steps_per_epoch * max_epochs   # 400X200=8000\n",
    "\n",
    "                    # 因为是从文件中读取数据，所以需要启动start_queue_runners()\n",
    "                    # 这个函数将会启动输入管道的线程，填充样本到队列中，以便出队操作可以从队列中拿到样本。            \n",
    "                    coord = tf.train.Coordinator()\n",
    "                    threads = tf.train.start_queue_runners(coord=coord)          \n",
    "\n",
    "                    # 运行训练集        \n",
    "                    print (\"begin trainning......\")\n",
    "                    print (\"max_steps:\",max_steps)           \n",
    "                    start = time.time()\n",
    "                    for step in range(max_steps):\n",
    "                        def should(freq):\n",
    "                            return freq > 0 and ((step + 1) % freq == 0 or step == max_steps - 1)\n",
    "                        print (\"step:\",step) \n",
    "\n",
    "                        # 定义一个需要run的所有操作的字典\n",
    "                        fetches = {\n",
    "                            \"train\": model.train              \n",
    "                        }\n",
    "\n",
    "                        # progress_freq为 50，每50次计算一次三个损失，显示进度\n",
    "                        if should(progress_freq):\n",
    "                            fetches[\"discrim_loss\"] = model.discrim_loss\n",
    "                            fetches[\"gen_loss_GAN\"] = model.gen_loss_GAN\n",
    "                            fetches[\"gen_loss_L1\"] = model.gen_loss_L1\n",
    "\n",
    "                        # display_freq为 50，每50次保存一次输入、目标、输出的图像\n",
    "                        if should(display_freq):\n",
    "                            fetches[\"display\"] = display_fetches\n",
    "\n",
    "                        # 运行各种操作，\n",
    "                        results = sess.run(fetches)            \n",
    "\n",
    "                        # display_freq为 50，每50次保存输入、目标、输出的图像\n",
    "                        if should(display_freq):\n",
    "                            print(\"saving display images\")\n",
    "                            filesets = save_images(train_output_dir,results[\"display\"], step=step)\n",
    "                            append_index(train_output_dir,filesets, step=True)  \n",
    "\n",
    "                        # progress_freq为 50，每50次打印一次三种损失的大小，显示进度\n",
    "                        if should(progress_freq):\n",
    "                            # global_step will have the correct step count if we resume from a checkpoint\n",
    "                            train_epoch = math.ceil(step/examples.steps_per_epoch)\n",
    "                            train_step = (step - 1) % examples.steps_per_epoch + 1\n",
    "                            rate = (step + 1) * batch_size / (time.time() - start)\n",
    "                            remaining = (max_steps - step) * batch_size / rate\n",
    "                            print(\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\" % (train_epoch, train_step, rate, remaining / 60))\n",
    "                            print(\"discrim_loss\", results[\"discrim_loss\"])\n",
    "                            print(\"gen_loss_GAN\", results[\"gen_loss_GAN\"])\n",
    "                            print(\"gen_loss_L1\", results[\"gen_loss_L1\"])\n",
    "\n",
    "                        # save_freq为500，每500次保存一次模型\n",
    "                        if should(save_freq):\n",
    "                            print(\"saving model\")\n",
    "                            saver.save(sess, os.path.join(train_output_dir, \"model\"), global_step=step)\n",
    "\n",
    "            # 测试\n",
    "            def test():\n",
    "             # 设置随机数种子的值\n",
    "                global seed\n",
    "                if seed is None:\n",
    "                    seed = random.randint(0, 2**31 - 1)\n",
    "\n",
    "                tf.set_random_seed(seed)\n",
    "                np.random.seed(seed)\n",
    "                random.seed(seed)\n",
    "\n",
    "                # 创建目录\n",
    "                if not os.path.exists(test_output_dir):\n",
    "                    os.makedirs(test_output_dir)\n",
    "                if checkpoint is None:\n",
    "                    raise Exception(\"checkpoint required for test mode\")\n",
    "\n",
    "                # disable these features in test mode\n",
    "                #scale_size = CROP_SIZE\n",
    "                #flip = False\n",
    "\n",
    "                # 加载数据集，得到输入数据和目标数据\n",
    "                examples = load_examples(test_input_dir)\n",
    "                print(\"load successful ! examples count = %d\" % examples.count)\n",
    "\n",
    "                # 创建模型，inputs和targets是：[batch_size, height, width, channels]\n",
    "                model = create_model(examples.inputs, examples.targets)\n",
    "                print (\"create model successful!\")\n",
    "\n",
    "\n",
    "                #图像处理[-1, 1] => [0, 1]\n",
    "                inputs = deprocess(examples.inputs)  \n",
    "                targets = deprocess(examples.targets)\n",
    "                outputs = deprocess(model.outputs)\n",
    "\n",
    "                # 把[0,1]的像素点转为RGB值：[0,255]\n",
    "                with tf.name_scope(\"convert_inputs\"):\n",
    "                    converted_inputs = convert(inputs)\n",
    "                with tf.name_scope(\"convert_targets\"):\n",
    "                    converted_targets = convert(targets)\n",
    "                with tf.name_scope(\"convert_outputs\"):\n",
    "                    converted_outputs = convert(outputs)\n",
    "\n",
    "\n",
    "                # 对图像进行编码以便于保存\n",
    "                with tf.name_scope(\"encode_images\"):\n",
    "                    display_fetches = {\n",
    "                        \"paths\": examples.paths,\n",
    "                        # tf.map_fn接受一个函数对象和集合，用函数对集合中每个元素分别处理\n",
    "                        \"inputs\": tf.map_fn(tf.image.encode_png, converted_inputs, dtype=tf.string, name=\"input_pngs\"),\n",
    "                        \"targets\": tf.map_fn(tf.image.encode_png, converted_targets, dtype=tf.string, name=\"target_pngs\"),\n",
    "                        \"outputs\": tf.map_fn(tf.image.encode_png, converted_outputs, dtype=tf.string, name=\"output_pngs\"),\n",
    "                    }\n",
    "\n",
    "                sess=tf.InteractiveSession()  \n",
    "                saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "                ckpt=tf.train.get_checkpoint_state(checkpoint)\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                coord = tf.train.Coordinator()\n",
    "                threads = tf.train.start_queue_runners(coord=coord) \n",
    "                for step in range(examples.count):\n",
    "                    results = sess.run(display_fetches)\n",
    "                    filesets = save_images(test_output_dir,results)\n",
    "                    for i, f in enumerate(filesets):\n",
    "                        print(\"evaluated image\", f[\"name\"])\n",
    "                    index_path = append_index(test_output_dir,filesets)\n",
    "                print(\"wrote index at\", index_path)\n",
    "                print(\"rate\", (time.time() - start) / max_steps)\n",
    "                \n",
    "            if __name__ == '__main__':\n",
    "                train()\n",
    "                #test()\n",
    "            tf.reset_default_graph()\n",
    "            time.sleep(10)\n",
    "            b+=1\n",
    "        c+=1"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
